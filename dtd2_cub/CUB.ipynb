{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea1a1b1-6d13-4a1b-bfb8-8b5f909a45d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import importlib\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# os.chdir('/your/path/to/Clip')\n",
    "!pwd\n",
    "!echo $CUDA_VISIBLE_DEVICES\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51d7bbe0-3c8e-43ea-ad1e-6fd3db46b42e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUB dataset ready.\n"
     ]
    }
   ],
   "source": [
    "from dtd2.applications.fine_grained_classification.cub_dataset import CUBDataset\n",
    "cub_data = CUBDataset(split='test', data_path='data/CUB_200_2011')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ab20c8d-b5a5-421b-9c57-36110c1d121e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['blue', 'brown', 'iridescent', 'purple', 'rufous', 'grey', 'yellow', 'olive', 'green', 'pink', 'orange', 'black', 'white', 'red', 'buff', 'solid', 'spotted', 'striped', 'multi-colored', 'malar', 'crested', 'masked', 'unique_pattern', 'eyebrow', 'eyering', 'plain', 'eyeline', 'capped']\n"
     ]
    }
   ],
   "source": [
    "adj_to_att = dict()\n",
    "\n",
    "for att_i, att in enumerate(cub_data.att_names):\n",
    "    context, adj = att.split('::')\n",
    "    skip = False\n",
    "    for w in ['length', 'size', 'shape', 'bill', 'eye', 'nape', 'crown']:\n",
    "        if w in context:\n",
    "            skip = True\n",
    "            break\n",
    "    if skip:\n",
    "        continue\n",
    "    if adj in adj_to_att:\n",
    "        adj_to_att[adj].append(att_i)\n",
    "    else:\n",
    "        adj_to_att[adj] = [att_i]\n",
    "\n",
    "print(list(adj_to_att.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6dfe6a39-7d83-4714-a8d8-9d7c83a8ba17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TextureDescriptionData ready. \n",
      "655 phrases with frequency above 10.\n",
      "Image count: train 3222, val 805, test 1342\n",
      "17 ['blue', 'brown', 'iridescent', 'purple', 'grey', 'yellow', 'green', 'pink', 'orange', 'black', 'white', 'red', 'solid', 'spotted', 'striped', 'multi-colored', 'plain']\n"
     ]
    }
   ],
   "source": [
    "from dtd2.data_api.dataset_api import TextureDescriptionData\n",
    "dtd2_data = TextureDescriptionData(phid_format=None)\n",
    "\n",
    "phrases = [adj for adj in adj_to_att.keys() if adj in dtd2_data.phrases]\n",
    "print(len(phrases), phrases)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37ecd3f2-564a-465a-9564-5ceaca379981",
   "metadata": {},
   "outputs": [],
   "source": [
    "att_to_adj_mat = np.zeros((len(cub_data.att_names), len(phrases)))\n",
    "for ph_i, ph in enumerate(phrases):\n",
    "    for att_i in adj_to_att[ph]:\n",
    "        att_to_adj_mat[att_i, ph_i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bdfd930-4263-4275-accc-c78d924af483",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_paths = [os.path.join('data/CUB_200_2011/images', d['img_name']) for d in cub_data.img_data_list]\n",
    "img_html_paths = [os.path.join('http://maxwell.cs.umass.edu/chenyun/data/CUB_200_2011/images', d['img_name']) for d in cub_data.img_data_list]\n",
    "gt_matrix = np.dot(cub_data.gt_att_labels, att_to_adj_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba0ab12d-511c-4abb-8529-46381d30e407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5794 5794 (5794, 17)\n"
     ]
    }
   ],
   "source": [
    "img_paths = [img_paths[i] for i in cub_data.img_splits['test']]\n",
    "img_html_paths = [img_html_paths[i] for i in cub_data.img_splits['test']]\n",
    "gt_matrix = np.stack([gt_matrix[i] for i in cub_data.img_splits['test']])\n",
    "print(len(cub_data.img_splits['test']), len(img_paths), gt_matrix.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "272c8e38-8a02-4815-b3d3-4c2d0d5def71",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClipEncoder ready.\n",
      "phrases encoded\n",
      "5666 remaining imgs\n",
      "5538 remaining imgs\n",
      "5410 remaining imgs\n",
      "5282 remaining imgs\n",
      "5154 remaining imgs\n",
      "5026 remaining imgs\n",
      "4898 remaining imgs\n",
      "4770 remaining imgs\n",
      "4642 remaining imgs\n",
      "4514 remaining imgs\n",
      "4386 remaining imgs\n",
      "4258 remaining imgs\n",
      "4130 remaining imgs\n",
      "4002 remaining imgs\n",
      "3874 remaining imgs\n",
      "3746 remaining imgs\n",
      "3618 remaining imgs\n",
      "3490 remaining imgs\n",
      "3362 remaining imgs\n",
      "3234 remaining imgs\n",
      "3106 remaining imgs\n",
      "2978 remaining imgs\n",
      "2850 remaining imgs\n",
      "2722 remaining imgs\n",
      "2594 remaining imgs\n",
      "2466 remaining imgs\n",
      "2338 remaining imgs\n",
      "2210 remaining imgs\n",
      "2082 remaining imgs\n",
      "1954 remaining imgs\n",
      "1826 remaining imgs\n",
      "1698 remaining imgs\n",
      "1570 remaining imgs\n",
      "1442 remaining imgs\n",
      "1314 remaining imgs\n",
      "1186 remaining imgs\n",
      "1058 remaining imgs\n",
      "930 remaining imgs\n",
      "802 remaining imgs\n",
      "674 remaining imgs\n",
      "546 remaining imgs\n",
      "418 remaining imgs\n",
      "290 remaining imgs\n",
      "162 remaining imgs\n",
      "34 remaining imgs\n",
      "imgs encoded\n"
     ]
    }
   ],
   "source": [
    "from utils.clip_encoder import ClipEncoder\n",
    "clip_encoder = ClipEncoder()\n",
    "\n",
    "text_l = ['An image of a %s bird' % p for p in phrases]\n",
    "phrase_vecs = clip_encoder.encode_text_list(text_l)\n",
    "print('phrases encoded')\n",
    "\n",
    "img_vecs = clip_encoder.encode_imgs(img_paths)\n",
    "print('imgs encoded')\n",
    "\n",
    "clip_scores = img_vecs @ phrase_vecs.T\n",
    "clip_scores = clip_scores.float().softmax(dim=-1).cpu()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8c4ae929-9549-4ee4-9fb6-b92778b1afde",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClipEncoder ready.\n",
      "CLIPP ready\n",
      "phrases encoded\n",
      "5666 remaining imgs\n",
      "5538 remaining imgs\n",
      "5410 remaining imgs\n",
      "5282 remaining imgs\n",
      "5154 remaining imgs\n",
      "5026 remaining imgs\n",
      "4898 remaining imgs\n",
      "4770 remaining imgs\n",
      "4642 remaining imgs\n",
      "4514 remaining imgs\n",
      "4386 remaining imgs\n",
      "4258 remaining imgs\n",
      "4130 remaining imgs\n",
      "4002 remaining imgs\n",
      "3874 remaining imgs\n",
      "3746 remaining imgs\n",
      "3618 remaining imgs\n",
      "3490 remaining imgs\n",
      "3362 remaining imgs\n",
      "3234 remaining imgs\n",
      "3106 remaining imgs\n",
      "2978 remaining imgs\n",
      "2850 remaining imgs\n",
      "2722 remaining imgs\n",
      "2594 remaining imgs\n",
      "2466 remaining imgs\n",
      "2338 remaining imgs\n",
      "2210 remaining imgs\n",
      "2082 remaining imgs\n",
      "1954 remaining imgs\n",
      "1826 remaining imgs\n",
      "1698 remaining imgs\n",
      "1570 remaining imgs\n",
      "1442 remaining imgs\n",
      "1314 remaining imgs\n",
      "1186 remaining imgs\n",
      "1058 remaining imgs\n",
      "930 remaining imgs\n",
      "802 remaining imgs\n",
      "674 remaining imgs\n",
      "546 remaining imgs\n",
      "418 remaining imgs\n",
      "290 remaining imgs\n",
      "162 remaining imgs\n",
      "34 remaining imgs\n",
      "imgs encoded\n"
     ]
    }
   ],
   "source": [
    "from utils.clip_plus import ClipPlusEncoder\n",
    "clipp_encoder = ClipPlusEncoder(load_path='output/clipp/models/prompt_lr0.001/clipp_epoch100.pth')\n",
    "\n",
    "text_l = ['An image of a %s bird' % p for p in phrases]\n",
    "with torch.no_grad():\n",
    "    phrase_vecs = clipp_encoder.encode_text_list(text_l)\n",
    "    print('phrases encoded')\n",
    "\n",
    "    img_vecs = clipp_encoder.encode_imgs(img_paths)\n",
    "    print('imgs encoded')\n",
    "\n",
    "clipp_scores = img_vecs @ phrase_vecs.T\n",
    "clipp_scores = clipp_scores.float().softmax(dim=-1).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7cf5d835-e3e0-4c37-b953-c4223343bc67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STAT clip_scores: shape torch.Size([5794, 17]) device cpu; mean 0.059; min 0.053; max 0.065; std 0.001\n",
      "STAT clipp_scores: shape torch.Size([5794, 17]) device cpu; mean 0.059; min 0.001; max 0.873; std 0.055\n",
      "STAT : shape torch.Size([5794, 17]) device cpu; mean 0.000; min -0.809; max 0.056; std 0.055\n"
     ]
    }
   ],
   "source": [
    "from dtd2.models.layers.util import print_tensor_stats\n",
    "print_tensor_stats(clip_scores, 'clip_scores')\n",
    "print_tensor_stats(clipp_scores, 'clipp_scores')\n",
    "print_tensor_stats(clip_scores - clipp_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298449c5-ac78-4c94-9e7f-f7f01d254498",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils.dtd2_triplet_encoder import TripletEncoder\n",
    "dtd2_encoder = TripletEncoder()\n",
    "\n",
    "phrase_vecs = dtd2_encoder.encode_text_list(phrases)\n",
    "print('phrases encoded: ', phrase_vecs.shape)\n",
    "\n",
    "img_vecs = dtd2_encoder.encode_imgs(img_paths)\n",
    "print('imgs encoded: ', img_vecs.shape)\n",
    "\n",
    "img_num = len(img_paths)\n",
    "phrase_num = len(phrases)\n",
    "\n",
    "neg_distances = torch.zeros((img_num, phrase_num))\n",
    "with torch.no_grad():\n",
    "    for img_i in range(img_num):\n",
    "        for ph_i in range(phrase_num):\n",
    "            v1 = img_vecs[img_i]\n",
    "            v2 = phrase_vecs[ph_i]\n",
    "            neg_distances[img_i, ph_i] = - dtd2_encoder.dist(v1, v2)\n",
    "        if img_i % 100 == 0:\n",
    "            print(img_i)\n",
    "\n",
    "print_tensor_stats(neg_distances, 'pred_scores')\n",
    "mdtd2_scores = neg_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7b302a57-2da5-4676-8924-b4c145b4b799",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1., 11., 17., ..., 16., 16., 32.])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(gt_matrix, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "32cb8907-6724-4906-ae96-73d6d9ebe969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP\n",
      "image to phrase\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/nfs/work1/elm/chenyun/Clip/dependencies/DescribingTextures/dtd2/data_api/utils/retrieval_metrics.py:146: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = np.nan_to_num(pred_num * 1.0 / gt_count)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_average_precision: 0.5406\n",
      "mean_reciprocal_rank: 0.7593\n",
      "precision_at_001: 0.6151\n",
      "precision_at_005: 0.4321\n",
      "precision_at_010: 0.3621\n",
      "precision_at_020: -1.0000\n",
      "precision_at_050: -1.0000\n",
      "precision_at_100: -1.0000\n",
      "query_average_precisions: [list, skipped]\n",
      "r_precision: 0.3055\n",
      "recall_at_001: 0.1292\n",
      "recall_at_005: 0.4343\n",
      "recall_at_010: 0.7110\n",
      "recall_at_020: -1.0000\n",
      "recall_at_050: -1.0000\n",
      "recall_at_100: -1.0000\n",
      "latex string\n",
      "mean_average_precision & mean_reciprocal_rank & precision_at_005 & precision_at_020 & recall_at_005 & recall_at_020\n",
      "54.06 & 75.93 & 43.21 & -100.00 & 43.43 & -100.00\n",
      "phrase to image\n",
      "mean_average_precision: 0.5014\n",
      "mean_reciprocal_rank: 0.9171\n",
      "precision_at_001: 0.8824\n",
      "precision_at_005: 0.7294\n",
      "precision_at_010: 0.7353\n",
      "precision_at_020: 0.7176\n",
      "precision_at_050: 0.7047\n",
      "precision_at_100: 0.6812\n",
      "query_average_precisions: [list, skipped]\n",
      "r_precision: 0.3055\n",
      "recall_at_001: 0.0012\n",
      "recall_at_005: 0.0046\n",
      "recall_at_010: 0.0090\n",
      "recall_at_020: 0.0160\n",
      "recall_at_050: 0.0375\n",
      "recall_at_100: 0.0713\n",
      "latex string\n",
      "mean_average_precision & mean_reciprocal_rank & precision_at_005 & precision_at_020 & recall_at_005 & recall_at_020\n",
      "50.14 & 91.71 & 72.94 & 71.76 & 0.46 & 1.60\n",
      "CLIPP\n",
      "image to phrase\n",
      "mean_average_precision: 0.4749\n",
      "mean_reciprocal_rank: 0.7134\n",
      "precision_at_001: 0.5599\n",
      "precision_at_005: 0.3623\n",
      "precision_at_010: 0.3067\n",
      "precision_at_020: -1.0000\n",
      "precision_at_050: -1.0000\n",
      "precision_at_100: -1.0000\n",
      "query_average_precisions: [list, skipped]\n",
      "r_precision: 0.3055\n",
      "recall_at_001: 0.1148\n",
      "recall_at_005: 0.3544\n",
      "recall_at_010: 0.5927\n",
      "recall_at_020: -1.0000\n",
      "recall_at_050: -1.0000\n",
      "recall_at_100: -1.0000\n",
      "latex string\n",
      "mean_average_precision & mean_reciprocal_rank & precision_at_005 & precision_at_020 & recall_at_005 & recall_at_020\n",
      "47.49 & 71.34 & 36.23 & -100.00 & 35.44 & -100.00\n",
      "phrase to image\n",
      "mean_average_precision: 0.4526\n",
      "mean_reciprocal_rank: 0.8333\n",
      "precision_at_001: 0.7059\n",
      "precision_at_005: 0.7059\n",
      "precision_at_010: 0.6529\n",
      "precision_at_020: 0.6382\n",
      "precision_at_050: 0.6035\n",
      "precision_at_100: 0.6024\n",
      "query_average_precisions: [list, skipped]\n",
      "r_precision: 0.3055\n",
      "recall_at_001: 0.0005\n",
      "recall_at_005: 0.0039\n",
      "recall_at_010: 0.0075\n",
      "recall_at_020: 0.0139\n",
      "recall_at_050: 0.0278\n",
      "recall_at_100: 0.0540\n",
      "latex string\n",
      "mean_average_precision & mean_reciprocal_rank & precision_at_005 & precision_at_020 & recall_at_005 & recall_at_020\n",
      "45.26 & 83.33 & 70.59 & 63.82 & 0.39 & 1.39\n"
     ]
    }
   ],
   "source": [
    "import utils.retrieval_compare as rc\n",
    "importlib.reload(rc)\n",
    "\n",
    "from utils.retrieval_compare import compare_pred_to_html\n",
    "\n",
    "# compare_pred_to_html(img_path_list=img_html_paths,\n",
    "#                      phrase_list=phrases,\n",
    "#                      phrase_weight=None,\n",
    "#                      gt_matrix=gt_matrix,\n",
    "#                      method_score_list=[['CLIP', clip_scores], ['DTD2', mdtd2_scores]],\n",
    "#                      output_path='output/retrieve_CUB_CLIP',\n",
    "#                      word_cloud=False)\n",
    "\n",
    "compare_pred_to_html(img_path_list=img_html_paths,\n",
    "                     phrase_list=phrases,\n",
    "                     phrase_weight=None,\n",
    "                     gt_matrix=gt_matrix,\n",
    "                     method_score_list=[['CLIP', clip_scores], ['CLIPP', clipp_scores]],\n",
    "                     output_path='output/retrieve_CUB_CLIPP',\n",
    "                     word_cloud=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b7736b73-fca6-447c-935d-175698b6bd45",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "has_bill_shape::curved_(up_or_down)\n",
      "has_bill_shape::dagger\n",
      "has_bill_shape::hooked\n",
      "has_bill_shape::needle\n",
      "has_bill_shape::hooked_seabird\n",
      "has_bill_shape::spatulate\n",
      "has_bill_shape::all-purpose\n",
      "has_bill_shape::cone\n",
      "has_bill_shape::specialized\n",
      "has_wing_color::blue\n",
      "has_wing_color::brown\n",
      "has_wing_color::iridescent\n",
      "has_wing_color::purple\n",
      "has_wing_color::rufous\n",
      "has_wing_color::grey\n",
      "has_wing_color::yellow\n",
      "has_wing_color::olive\n",
      "has_wing_color::green\n",
      "has_wing_color::pink\n",
      "has_wing_color::orange\n",
      "has_wing_color::black\n",
      "has_wing_color::white\n",
      "has_wing_color::red\n",
      "has_wing_color::buff\n",
      "has_upperparts_color::blue\n",
      "has_upperparts_color::brown\n",
      "has_upperparts_color::iridescent\n",
      "has_upperparts_color::purple\n",
      "has_upperparts_color::rufous\n",
      "has_upperparts_color::grey\n",
      "has_upperparts_color::yellow\n",
      "has_upperparts_color::olive\n",
      "has_upperparts_color::green\n",
      "has_upperparts_color::pink\n",
      "has_upperparts_color::orange\n",
      "has_upperparts_color::black\n",
      "has_upperparts_color::white\n",
      "has_upperparts_color::red\n",
      "has_upperparts_color::buff\n",
      "has_underparts_color::blue\n",
      "has_underparts_color::brown\n",
      "has_underparts_color::iridescent\n",
      "has_underparts_color::purple\n",
      "has_underparts_color::rufous\n",
      "has_underparts_color::grey\n",
      "has_underparts_color::yellow\n",
      "has_underparts_color::olive\n",
      "has_underparts_color::green\n",
      "has_underparts_color::pink\n",
      "has_underparts_color::orange\n",
      "has_underparts_color::black\n",
      "has_underparts_color::white\n",
      "has_underparts_color::red\n",
      "has_underparts_color::buff\n",
      "has_breast_pattern::solid\n",
      "has_breast_pattern::spotted\n",
      "has_breast_pattern::striped\n",
      "has_breast_pattern::multi-colored\n",
      "has_back_color::blue\n",
      "has_back_color::brown\n",
      "has_back_color::iridescent\n",
      "has_back_color::purple\n",
      "has_back_color::rufous\n",
      "has_back_color::grey\n",
      "has_back_color::yellow\n",
      "has_back_color::olive\n",
      "has_back_color::green\n",
      "has_back_color::pink\n",
      "has_back_color::orange\n",
      "has_back_color::black\n",
      "has_back_color::white\n",
      "has_back_color::red\n",
      "has_back_color::buff\n",
      "has_tail_shape::forked_tail\n",
      "has_tail_shape::rounded_tail\n",
      "has_tail_shape::notched_tail\n",
      "has_tail_shape::fan-shaped_tail\n",
      "has_tail_shape::pointed_tail\n",
      "has_tail_shape::squared_tail\n",
      "has_upper_tail_color::blue\n",
      "has_upper_tail_color::brown\n",
      "has_upper_tail_color::iridescent\n",
      "has_upper_tail_color::purple\n",
      "has_upper_tail_color::rufous\n",
      "has_upper_tail_color::grey\n",
      "has_upper_tail_color::yellow\n",
      "has_upper_tail_color::olive\n",
      "has_upper_tail_color::green\n",
      "has_upper_tail_color::pink\n",
      "has_upper_tail_color::orange\n",
      "has_upper_tail_color::black\n",
      "has_upper_tail_color::white\n",
      "has_upper_tail_color::red\n",
      "has_upper_tail_color::buff\n",
      "has_head_pattern::spotted\n",
      "has_head_pattern::malar\n",
      "has_head_pattern::crested\n",
      "has_head_pattern::masked\n",
      "has_head_pattern::unique_pattern\n",
      "has_head_pattern::eyebrow\n",
      "has_head_pattern::eyering\n",
      "has_head_pattern::plain\n",
      "has_head_pattern::eyeline\n",
      "has_head_pattern::striped\n",
      "has_head_pattern::capped\n",
      "has_breast_color::blue\n",
      "has_breast_color::brown\n",
      "has_breast_color::iridescent\n",
      "has_breast_color::purple\n",
      "has_breast_color::rufous\n",
      "has_breast_color::grey\n",
      "has_breast_color::yellow\n",
      "has_breast_color::olive\n",
      "has_breast_color::green\n",
      "has_breast_color::pink\n",
      "has_breast_color::orange\n",
      "has_breast_color::black\n",
      "has_breast_color::white\n",
      "has_breast_color::red\n",
      "has_breast_color::buff\n",
      "has_throat_color::blue\n",
      "has_throat_color::brown\n",
      "has_throat_color::iridescent\n",
      "has_throat_color::purple\n",
      "has_throat_color::rufous\n",
      "has_throat_color::grey\n",
      "has_throat_color::yellow\n",
      "has_throat_color::olive\n",
      "has_throat_color::green\n",
      "has_throat_color::pink\n",
      "has_throat_color::orange\n",
      "has_throat_color::black\n",
      "has_throat_color::white\n",
      "has_throat_color::red\n",
      "has_throat_color::buff\n",
      "has_eye_color::blue\n",
      "has_eye_color::brown\n",
      "has_eye_color::purple\n",
      "has_eye_color::rufous\n",
      "has_eye_color::grey\n",
      "has_eye_color::yellow\n",
      "has_eye_color::olive\n",
      "has_eye_color::green\n",
      "has_eye_color::pink\n",
      "has_eye_color::orange\n",
      "has_eye_color::black\n",
      "has_eye_color::white\n",
      "has_eye_color::red\n",
      "has_eye_color::buff\n",
      "has_bill_length::about_the_same_as_head\n",
      "has_bill_length::longer_than_head\n",
      "has_bill_length::shorter_than_head\n",
      "has_forehead_color::blue\n",
      "has_forehead_color::brown\n",
      "has_forehead_color::iridescent\n",
      "has_forehead_color::purple\n",
      "has_forehead_color::rufous\n",
      "has_forehead_color::grey\n",
      "has_forehead_color::yellow\n",
      "has_forehead_color::olive\n",
      "has_forehead_color::green\n",
      "has_forehead_color::pink\n",
      "has_forehead_color::orange\n",
      "has_forehead_color::black\n",
      "has_forehead_color::white\n",
      "has_forehead_color::red\n",
      "has_forehead_color::buff\n",
      "has_under_tail_color::blue\n",
      "has_under_tail_color::brown\n",
      "has_under_tail_color::iridescent\n",
      "has_under_tail_color::purple\n",
      "has_under_tail_color::rufous\n",
      "has_under_tail_color::grey\n",
      "has_under_tail_color::yellow\n",
      "has_under_tail_color::olive\n",
      "has_under_tail_color::green\n",
      "has_under_tail_color::pink\n",
      "has_under_tail_color::orange\n",
      "has_under_tail_color::black\n",
      "has_under_tail_color::white\n",
      "has_under_tail_color::red\n",
      "has_under_tail_color::buff\n",
      "has_nape_color::blue\n",
      "has_nape_color::brown\n",
      "has_nape_color::iridescent\n",
      "has_nape_color::purple\n",
      "has_nape_color::rufous\n",
      "has_nape_color::grey\n",
      "has_nape_color::yellow\n",
      "has_nape_color::olive\n",
      "has_nape_color::green\n",
      "has_nape_color::pink\n",
      "has_nape_color::orange\n",
      "has_nape_color::black\n",
      "has_nape_color::white\n",
      "has_nape_color::red\n",
      "has_nape_color::buff\n",
      "has_belly_color::blue\n",
      "has_belly_color::brown\n",
      "has_belly_color::iridescent\n",
      "has_belly_color::purple\n",
      "has_belly_color::rufous\n",
      "has_belly_color::grey\n",
      "has_belly_color::yellow\n",
      "has_belly_color::olive\n",
      "has_belly_color::green\n",
      "has_belly_color::pink\n",
      "has_belly_color::orange\n",
      "has_belly_color::black\n",
      "has_belly_color::white\n",
      "has_belly_color::red\n",
      "has_belly_color::buff\n",
      "has_wing_shape::rounded-wings\n",
      "has_wing_shape::pointed-wings\n",
      "has_wing_shape::broad-wings\n",
      "has_wing_shape::tapered-wings\n",
      "has_wing_shape::long-wings\n",
      "has_size::large_(16_-_32_in)\n",
      "has_size::small_(5_-_9_in)\n",
      "has_size::very_large_(32_-_72_in)\n",
      "has_size::medium_(9_-_16_in)\n",
      "has_size::very_small_(3_-_5_in)\n",
      "has_shape::upright-perching_water-like\n",
      "has_shape::chicken-like-marsh\n",
      "has_shape::long-legged-like\n",
      "has_shape::duck-like\n",
      "has_shape::owl-like\n",
      "has_shape::gull-like\n",
      "has_shape::hummingbird-like\n",
      "has_shape::pigeon-like\n",
      "has_shape::tree-clinging-like\n",
      "has_shape::hawk-like\n",
      "has_shape::sandpiper-like\n",
      "has_shape::upland-ground-like\n",
      "has_shape::swallow-like\n",
      "has_shape::perching-like\n",
      "has_back_pattern::solid\n",
      "has_back_pattern::spotted\n",
      "has_back_pattern::striped\n",
      "has_back_pattern::multi-colored\n",
      "has_tail_pattern::solid\n",
      "has_tail_pattern::spotted\n",
      "has_tail_pattern::striped\n",
      "has_tail_pattern::multi-colored\n",
      "has_belly_pattern::solid\n",
      "has_belly_pattern::spotted\n",
      "has_belly_pattern::striped\n",
      "has_belly_pattern::multi-colored\n",
      "has_primary_color::blue\n",
      "has_primary_color::brown\n",
      "has_primary_color::iridescent\n",
      "has_primary_color::purple\n",
      "has_primary_color::rufous\n",
      "has_primary_color::grey\n",
      "has_primary_color::yellow\n",
      "has_primary_color::olive\n",
      "has_primary_color::green\n",
      "has_primary_color::pink\n",
      "has_primary_color::orange\n",
      "has_primary_color::black\n",
      "has_primary_color::white\n",
      "has_primary_color::red\n",
      "has_primary_color::buff\n",
      "has_leg_color::blue\n",
      "has_leg_color::brown\n",
      "has_leg_color::iridescent\n",
      "has_leg_color::purple\n",
      "has_leg_color::rufous\n",
      "has_leg_color::grey\n",
      "has_leg_color::yellow\n",
      "has_leg_color::olive\n",
      "has_leg_color::green\n",
      "has_leg_color::pink\n",
      "has_leg_color::orange\n",
      "has_leg_color::black\n",
      "has_leg_color::white\n",
      "has_leg_color::red\n",
      "has_leg_color::buff\n",
      "has_bill_color::blue\n",
      "has_bill_color::brown\n",
      "has_bill_color::iridescent\n",
      "has_bill_color::purple\n",
      "has_bill_color::rufous\n",
      "has_bill_color::grey\n",
      "has_bill_color::yellow\n",
      "has_bill_color::olive\n",
      "has_bill_color::green\n",
      "has_bill_color::pink\n",
      "has_bill_color::orange\n",
      "has_bill_color::black\n",
      "has_bill_color::white\n",
      "has_bill_color::red\n",
      "has_bill_color::buff\n",
      "has_crown_color::blue\n",
      "has_crown_color::brown\n",
      "has_crown_color::iridescent\n",
      "has_crown_color::purple\n",
      "has_crown_color::rufous\n",
      "has_crown_color::grey\n",
      "has_crown_color::yellow\n",
      "has_crown_color::olive\n",
      "has_crown_color::green\n",
      "has_crown_color::pink\n",
      "has_crown_color::orange\n",
      "has_crown_color::black\n",
      "has_crown_color::white\n",
      "has_crown_color::red\n",
      "has_crown_color::buff\n",
      "has_wing_pattern::solid\n",
      "has_wing_pattern::spotted\n",
      "has_wing_pattern::striped\n",
      "has_wing_pattern::multi-colored\n"
     ]
    }
   ],
   "source": [
    "for n in cub_data.att_names:\n",
    "    print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83821d72-f576-4e58-97c0-314805f8d556",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clip",
   "language": "python",
   "name": "clip"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
