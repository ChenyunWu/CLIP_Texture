{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42dbcf17-095f-470b-9aad-c276596dce14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/chenyun/work1/Clip\n",
      "4\n",
      "Sat Aug 21 16:03:48 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.57.02    Driver Version: 470.57.02    CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Quadro RTX 8000     Off  | 00000000:1A:00.0 Off |                  Off |\n",
      "| 37%   63C    P2   239W / 260W |  46632MiB / 48601MiB |     88%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Quadro RTX 8000     Off  | 00000000:1C:00.0 Off |                  Off |\n",
      "| 46%   69C    P2   243W / 260W |  43746MiB / 48601MiB |     23%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Quadro RTX 8000     Off  | 00000000:1D:00.0 Off |                  Off |\n",
      "| 50%   72C    P2   215W / 260W |  43730MiB / 48601MiB |     42%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Quadro RTX 8000     Off  | 00000000:1E:00.0 Off |                  Off |\n",
      "| 48%   70C    P2   216W / 260W |  43730MiB / 48601MiB |     45%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  Quadro RTX 8000     Off  | 00000000:3D:00.0 Off |                  Off |\n",
      "| 33%   32C    P8    14W / 260W |   2743MiB / 48601MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  Quadro RTX 8000     Off  | 00000000:3F:00.0 Off |                  Off |\n",
      "| 33%   34C    P8    16W / 260W |      0MiB / 48601MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  Quadro RTX 8000     Off  | 00000000:40:00.0 Off |                  Off |\n",
      "| 41%   66C    P2   265W / 260W |  44748MiB / 48601MiB |     71%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  Quadro RTX 8000     Off  | 00000000:41:00.0 Off |                  Off |\n",
      "| 42%   66C    P2   222W / 260W |  44494MiB / 48601MiB |     81%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A    112382      C   python                          46627MiB |\n",
      "|    1   N/A  N/A    112382      C   python                          43741MiB |\n",
      "|    2   N/A  N/A    112382      C   python                          43725MiB |\n",
      "|    3   N/A  N/A    112382      C   python                          43725MiB |\n",
      "|    4   N/A  N/A     28588      C   ...nda3/envs/clip/bin/python     1297MiB |\n",
      "|    4   N/A  N/A     29835      C   ...nda3/envs/clip/bin/python     1443MiB |\n",
      "|    6   N/A  N/A    126995      C   ...on/3.7.4-1910/bin/python3    44745MiB |\n",
      "|    7   N/A  N/A    126996      C   ...on/3.7.4-1910/bin/python3    44491MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import importlib\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "os.chdir('/home/chenyun/work1/Clip')\n",
    "!pwd\n",
    "!echo $CUDA_VISIBLE_DEVICES\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4f84c38-c76e-41db-b510-169a6ab3b969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClipEncoder ready.\n"
     ]
    }
   ],
   "source": [
    "from utils.clip_encoder import ClipEncoder\n",
    "clip_encoder = ClipEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef8464a1-01bc-41cd-b0fc-3224bab493c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['info', 'img_all_id', 'annotations']\n",
      "['info', 'img_all_id', 'annotations']\n",
      "4700\n",
      "2350\n",
      "{'img2_id': '0905533', 'img1_id': '0715395', 'sentences2': ['flying in the air', 'stabilizer bottom of the tail', 'facing left', 'small size', 'propeller engine'], 'id': 0, 'sentences1': ['on the ground', 'stabilizer top of the tail', 'facing right', 'medium size', 'turbo fan engine']}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "train_data = json.load(open('data/VisDiff/visdiff_train.json'))\n",
    "test_data = json.load(open('data/VisDiff/visdiff_test.json'))\n",
    "print(list(train_data.keys()))\n",
    "print(list(test_data.keys()))\n",
    "print(len(train_data['annotations']))\n",
    "print(len(test_data['annotations']))\n",
    "print(test_data['annotations'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2cf8fbc1-e54d-43f9-aee8-e8963e966664",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_phrases = dict()\n",
    "for img_name in dataset.img_splits['train']:\n",
    "    img_data = dataset.img_data_dict[img_name]\n",
    "    if img_data['category'] not in cat_phrases:\n",
    "        cat_phrases[img_data['category']] = np.zeros(656)\n",
    "    for p_id in img_data['phrase_ids']:\n",
    "        if p_id >= 0:\n",
    "            cat_phrases[img_data['category']][p_id] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f0d83095-d7f9-486c-a5dc-95bf874d7b7d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.3986587183308495\n",
      "5 0.485096870342772\n",
      "10 0.5007451564828614\n",
      "15 0.5253353204172876\n",
      "20 0.5484351713859911\n",
      "25 0.5320417287630402\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Input An image of blotchy, splotchy, stained, green, smeared, mottled, painting, spotted, grungy, spotty, multi color, brown, marbled, veined, bleached, purple, soft texture, scratched, painted, patchy, speckled, marked, freckled, dappled, abstract, messy, splattered, botany, bright, patched texture. is too long for context length 77",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-4300d7ba96f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mcat_to_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategories\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mtext_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcat_desc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcategories\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mtext_feats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclip_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode_text_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mimg_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_splits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/nfs/work1/elm/chenyun/Clip/utils/clip_encoder.py\u001b[0m in \u001b[0;36mencode_text_list\u001b[0;34m(self, text_list, batch_size)\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%d remaining texts'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_list\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0mtext_feats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode_text_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_feats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/nfs/work1/elm/chenyun/Clip/utils/clip_encoder.py\u001b[0m in \u001b[0;36mencode_text_batch\u001b[0;34m(self, text_list)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mencode_text_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0mtext_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/nfs/work1/elm/chenyun/Clip/utils/clip_encoder.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mencode_text_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0mtext_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/clip/lib/python3.7/site-packages/clip/clip.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(texts, context_length, truncate)\u001b[0m\n\u001b[1;32m    216\u001b[0m                 \u001b[0mtokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meot_token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Input {texts[i]} is too long for context length {context_length}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m         \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Input An image of blotchy, splotchy, stained, green, smeared, mottled, painting, spotted, grungy, spotty, multi color, brown, marbled, veined, bleached, purple, soft texture, scratched, painted, patchy, speckled, marked, freckled, dappled, abstract, messy, splattered, botany, bright, patched texture. is too long for context length 77"
     ]
    }
   ],
   "source": [
    "ave_phrases = np.zeros(656)\n",
    "for p_count in cat_phrases.values():\n",
    "    ave_phrases += p_count\n",
    "ave_phrases /= len(cat_phrases)\n",
    "\n",
    "for p_num in [1, 5, 10, 15, 20, 25, 30, 35, 40]:\n",
    "    cat_desc = dict()\n",
    "    for cat, p_count in cat_phrases.items():\n",
    "        p_scores = (p_count - ave_phrases) / len(dataset.img_splits['train'])\n",
    "        pi_sorted = np.argsort(p_scores)\n",
    "        phrases = list()\n",
    "        for i in range(p_num):\n",
    "            pi = pi_sorted[-i - 1]\n",
    "            if p_scores[pi] < 0:\n",
    "                print('WARN: score < 0: %s, %d' % (cat, pi))\n",
    "                break\n",
    "            phrases.append(dataset.phid_to_phrase(pi))\n",
    "        cat_desc[cat] = 'An image of %s texture.' % ', '.join(phrases)\n",
    "    \n",
    "#     print(cat_desc)\n",
    "    categories = sorted(list(cat_desc.keys()))\n",
    "    cat_to_ids = {c: i for i, c in enumerate(categories)}\n",
    "    text_inputs = [cat_desc[c] for c in categories]\n",
    "    text_feats = clip_encoder.encode_text_list(text_inputs)\n",
    "    correct = 0\n",
    "    for img_name in dataset.img_splits['test']:\n",
    "        img = dataset.load_img(img_name)\n",
    "        img_feat = clip_encoder.encode_img(img)\n",
    "        score = img_feat @ text_feats.T\n",
    "        pred_ci = int(torch.argmax(score))\n",
    "        if pred_ci == cat_to_ids[img_name.split('/')[0]]:\n",
    "            correct += 1\n",
    "    acc = correct / len(dataset.img_splits['test'])\n",
    "    print(p_num, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "80a7b3a8-440d-4dbe-badc-f3470f2672c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = ['An image of %s texture.' % c for c in categories]\n",
    "text_feats = clip_encoder.encode_text_list(texts)\n",
    "correct = 0\n",
    "for img_name in dataset.img_splits['test']:\n",
    "    img = dataset.load_img(img_name)\n",
    "    img_feat = clip_encoder.encode_img(img)\n",
    "    score = img_feat @ text_feats.T\n",
    "    pred_ci = int(torch.argmax(score))\n",
    "    if pred_ci == cat_to_ids[img_name.split('/')[0]]:\n",
    "        correct += 1\n",
    "acc = correct / len(dataset.img_splits['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5cca8e3a-aef6-4f84-9115-d67d3efa354e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4105812220566319\n"
     ]
    }
   ],
   "source": [
    "print(acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clip",
   "language": "python",
   "name": "clip"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
